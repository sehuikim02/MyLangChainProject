{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PromptTemplate \n",
    "* [PromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.prompt.PromptTemplate.html#langchain_core.prompts.prompt.PromptTemplate)\n",
    "* [ChatPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatPromptTemplate.html#langchain_core.prompts.chat.ChatPromptTemplate)\n",
    "* [ChatMessagePromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.chat.ChatMessagePromptTemplate.html#langchain_core.prompts.chat.ChatMessagePromptTemplate)\n",
    "* [FewShotPromptTemplate](https://python.langchain.com/api_reference/core/prompts/langchain_core.prompts.few_shot.FewShotPromptTemplate.html#langchain_core.prompts.few_shot.FewShotPromptTemplate)\n",
    "* PartialPrompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# poetry add python-dotenv langchain langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) PromptTemplate 의 from_template() 함수 사용\n",
    "* 주로 LLM(텍스트 완성형 모델, ex. Ollama, GPT-3.5)과 함께 사용\n",
    "* 하나의 문자열 프롬프트를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ChatGPT는 대규모 텍스트 데이터를 사용해 다음에 올 단어를 예측하도록 하는 **자기지도 학습**으로 사전 학습됩니다. 이후 인간이 '\n",
      " '만든 질문‑답변 쌍 등으로 구성된 **지도 학습**과, 모델의 출력을 인간 피드백으로 평가해 보강하는 **강화 학습**(RLHF)을 거쳐 '\n",
      " '사용자의 의도에 맞는 답변을 생성하도록 미세 조정됩니다. 이렇게 단계별로 학습된 파라미터들은 입력된 문맥을 이해하고, 그에 맞는 '\n",
      " '자연스러운 언어 출력을 생성하는 기반이 됩니다.')\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from pprint import pprint\n",
    "\n",
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model = \"openai/gpt-oss-120b\",                # GPT-OSS-120B\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "chain = prompt_template | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3})\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) PromptTemplate 결합하기\n",
    "* 동일한 Prompt 패턴을 사용하지만 여러 개의 질문을 작성해서 LLM을 실행할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['count', 'language', 'model_name'] input_types={} partial_variables={} template='{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.'\n",
      "('**ChatGPT 모델의 학습 원리 (3문장)**  \\n'\n",
      " '1. 대규모 텍스트 데이터를 이용해 트랜스포머 기반의 언어 모델을 사전 학습(pre‑training)하고, 문맥을 예측하는 마스크드 언어 '\n",
      " '모델링과 다음 문장 예측 같은 목표를 최적화합니다.  \\n'\n",
      " '2. 사전 학습된 모델을 실제 대화나 특정 작업에 맞게 인간 피드백을 활용한 강화학습(RLHF) 단계에서 미세 '\n",
      " '조정(fine‑tuning)하여 응답 품질과 안전성을 높입니다.  \\n'\n",
      " '3. 학습 과정에서는 역전파와 옵티마이저(예: Adam)로 파라미터를 업데이트하며, 수십억 개의 파라미터가 서로 연결된 네트워크 형태로 '\n",
      " '지식을 내재화합니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT 모델의 장점 요약  \\n'\n",
      " '\\n'\n",
      " '- **다양한 언어와 도메인에 대한 높은 이해도**: 방대한 텍스트 코퍼스를 학습해 일상 대화, 전문 지식, 코딩 등 다양한 분야에서 '\n",
      " '자연스러운 응답을 생성합니다.  \\n'\n",
      " '- **문맥 유지 및 연속적인 대화**: 트랜스포머 구조가 긴 문맥을 효과적으로 처리해 이전 발언을 기억하고 일관된 흐름을 '\n",
      " '유지합니다.  \\n'\n",
      " '- **사용자 맞춤형 조정 가능**: RLHF와 파인튜닝을 통해 특정 목적(예: 고객 지원, 교육, 창작) 등에 맞춰 행동을 조정할 수 '\n",
      " '있어 유연성이 뛰어납니다.  \\n'\n",
      " '- **실시간 추론 속도**: 최적화된 모델 아키텍처와 하드웨어 가속 덕분에 빠른 응답 시간을 제공해 실시간 인터랙션에 적합합니다.  \\n'\n",
      " '\\n'\n",
      " '---\\n'\n",
      " '\\n'\n",
      " '### ChatGPT와 비슷한 AI 모델 (영어 명칭)\\n'\n",
      " '\\n'\n",
      " '- **GPT‑4** (OpenAI)  \\n'\n",
      " '- **LLaMA 2** (Meta)  \\n'\n",
      " '- **Claude** (Anthropic)  \\n'\n",
      " '- **Gemini** (Google DeepMind)  \\n'\n",
      " '- **Mistral** (Mistral AI)  \\n'\n",
      " '- **Falcon** (Technology Innovation Institute)  \\n'\n",
      " '- **Cohere Command** (Cohere)  \\n'\n",
      " '- **Bloom** (BigScience)  \\n'\n",
      " '- **OPT** (Meta)  \\n'\n",
      " '- **T5** (Google)  \\n'\n",
      " '\\n'\n",
      " '이 모델들은 모두 트랜스포머 기반의 대규모 언어 모델이며, 텍스트 생성, 이해, 그리고 대화 시스템 등에 활용됩니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "# 템플릿에 format()을 써서 값을 채워서 프롬프트를 완성\n",
    "filled_prompt = prompt_template.format(model_name=\"ChatGPT\", count=3)\n",
    "\n",
    "# 문자열 템플릿 결합 (PromptTemplate + PromptTemplate + 문자열)\n",
    "combined_prompt = (\n",
    "              prompt_template\n",
    "              + PromptTemplate.from_template(\"\\n\\n 그리고 {model_name} 모델의 장점을 요약 정리해 주세요\")\n",
    "              + \"\\n\\n {model_name} 모델과 비슷한 AI 모델은 어떤 것이 있나요? 모델명은 {language}로 답변해 주세요.\"\n",
    ")\n",
    "combined_prompt.format(model_name=\"ChatGPT\", count=3, language=\"영어\")\n",
    "print(combined_prompt)\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "chain = combined_prompt | llm | StrOutputParser()\n",
    "response = chain.invoke({\"model_name\":\"ChatGPT\", \"count\":3, \"language\":\"영어\"})\n",
    "\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PromptTemplate 의 파라미터를 배열 형태로 하여 여러개 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.', 'Gemini 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.', 'Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.']\n",
      "<class 'str'> GPT-4 모델의 학습 원리를 2 문장으로 한국어로 답변해 주세요.\n",
      "('GPT‑4는 대규모 텍스트 데이터를 이용해 다음에 올 단어를 예측하도록 하는 자기지도 학습(self‑supervised learning) '\n",
      " '과정을 거쳐, 언어의 통계적 패턴과 의미 관계를 내부 파라미터에 압축합니다. 학습이 끝난 후에는 인간의 피드백을 활용한 '\n",
      " '강화학습(RLHF)으로 답변 품질과 안전성을 추가로 조정합니다.')\n",
      "<class 'str'> Gemini 모델의 학습 원리를 3 문장으로 한국어로 답변해 주세요.\n",
      "('Gemini 모델은 대규모 텍스트와 멀티모달 데이터를 사용해 사전 학습(pre‑training) 단계에서 언어와 시각 정보를 동시에 '\n",
      " '학습합니다. 이후, 인간 피드백을 활용한 강화학습(RLHF) 과정을 거쳐 원하는 응답을 생성하도록 미세 조정합니다. 이러한 두 단계의 '\n",
      " '학습을 결합해 높은 이해력과 생성 능력을 갖춘 모델을 구현합니다.')\n",
      "<class 'str'> Claude 모델의 학습 원리를 4 문장으로 한국어로 답변해 주세요.\n",
      "('Claude 모델은 대규모 텍스트 데이터를 사용해 사전 학습(pre‑training)됩니다. 이 과정에서 트랜스포머 기반의 언어 모델이 '\n",
      " '문맥을 예측하도록 학습되어, 다음 토큰을 추정하는 확률을 최적화합니다. 이후 인간 피드백을 활용한 강화학습(RLHF) 단계에서, 모델이 '\n",
      " '생성한 답변을 사람 평가자가 순위 매기고, 이를 바탕으로 보상 모델을 만들어 정책을 미세 조정합니다. 최종적으로는 다양한 작업에 '\n",
      " '적합하도록 여러 도메인에서 추가 미세 튜닝을 수행해 실용성을 높입니다.')\n"
     ]
    }
   ],
   "source": [
    "template_text = \"{model_name} 모델의 학습 원리를 {count} 문장으로 한국어로 답변해 주세요.\"\n",
    "\n",
    "# PromptTemplate 인스턴스를 생성\n",
    "prompt_template = PromptTemplate.from_template(template_text)\n",
    "\n",
    "questions = [\n",
    "    {\"model_name\": \"GPT-4\", \"count\": 2},\n",
    "    {\"model_name\": \"Gemini\", \"count\": 3},\n",
    "    {\"model_name\": \"Claude\", \"count\": 4},\n",
    "]\n",
    "\n",
    "# 여러 개의 프롬프트를 미리 생성\n",
    "formatted_prompts = [prompt_template.format(**q) for q in questions]    # ** : 파라미터에 dict가 들어갈때 ** 사용\n",
    "print(formatted_prompts)  # 미리 생성된 질문 목록 확인\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "for prompt in formatted_prompts:\n",
    "    print(type(prompt), prompt)\n",
    "    response = llm.invoke(prompt)\n",
    "    pprint(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) ChatPromptTemplate\n",
    "* Tuple 형태의 system, user, assistant 메시지 지원\n",
    "* 여러 개의 메시지를 조합하여 LLM에게 전달 가능\n",
    "* 간결성과 가독성이 높고 단순한 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='This system is an expert in answering questions about AI. Please provide clear and detailed explanations.', additional_kwargs={}, response_metadata={}), HumanMessage(content='ChatGPT 모델의 학습 원리를 설명해 주세요.', additional_kwargs={}, response_metadata={})]\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## ChatGPT 모델의 학습 원리\n",
      "\n",
      "ChatGPT는 **대규모 트랜스포머(Transformer) 기반 언어 모델**이며, 크게 **두 단계**의 학습 과정을 거칩니다.\n",
      "\n",
      "1. **사전학습(Pre‑training)**\n",
      "2. **미세조정(Fine‑tuning)·RLHF(강화학습을 통한 인간 피드백)**  \n",
      "\n",
      "아래에서는 각각의 단계와 핵심 메커니즘을 상세히 살펴보겠습니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. 사전학습 (Pre‑training)\n",
      "\n",
      "| 단계 | 내용 | 핵심 포인트 |\n",
      "|------|------|--------------|\n",
      "| **데이터 수집** | 인터넷에 존재하는 방대한 텍스트(웹 페이지, 책, 논문, 대화 로그 등)를 크롤링하고, 저작권·품질을 고려해 필터링합니다. | 데이터 규모가 수백 GB ~ 수 TB 수준이며, 다양하고 풍부한 언어 현상을 포함합니다. |\n",
      "| **토크나이징 (Tokenization)** | 텍스트를 **토큰**(sub‑word 단위)으로 변환합니다. 일반적으로 **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 같은 알고리즘을 사용합니다. | 1개의 토큰은 보통 1~4개의 문자에 해당하고, 어휘집(vocabulary) 크기는 30k~100k 정도입니다. |\n",
      "| **모델 아키텍처** | **Transformer Decoder** 구조를 사용합니다. 주요 구성 요소: <br>• **Self‑Attention** (다중 헤드) <br>• **Feed‑Forward 네트워크** <br>• **Layer Normalization**, **Residual Connection** | Self‑Attention 은 입력 토큰들 간의 관계를 동적으로 학습해 “문맥”을 파악합니다. |\n",
      "| **학습 목표** | **다음 토큰 예측 (Next‑Token Prediction)** : 주어진 앞선 토큰 시퀀스 \\(x_{1:t-1}\\) 에서 \\(x_t\\) 를 맞추는 확률 \\(p(x_t|x_{1:t-1})\\) 를 최대화합니다. | 손실 함수는 **Cross‑Entropy Loss** 로, \\(-\\log p(x_t|x_{1:t-1})\\) 를 최소화합니다. |\n",
      "| **최적화** | **Stochastic Gradient Descent (SGD)** 계열, 보통 **Adam** 혹은 **AdamW** 옵티마이저를 사용합니다. <br>학습률 스케줄링(예: **Warm‑up → Linear Decay**)도 적용합니다. | 대규모 GPU/TPU 클러스터에서 **데이터 병렬(Data Parallel)** 혹은 **모델 병렬(Model Parallel)** 로 분산 학습합니다. |\n",
      "| **학습 규모** | 파라미터 수: 수억 ~ 수천억(예: GPT‑3 175B, GPT‑4 수조) <br>학습 토큰 수: 수조 토큰 | 파라미터와 데이터 양이 커질수록 **스케일링 법칙**에 따라 성능이 예측 가능하게 향상됩니다. |\n",
      "\n",
      "#### 핵심 메커니즘 – Self‑Attention\n",
      "1. **Query, Key, Value** 를 각각 선형 변환으로 만든다.  \n",
      "2. 각 토큰의 Query와 모든 토큰의 Key 사이의 내적을 구해 **스코어**를 만든다.  \n",
      "3. 스코어에 **softmax**를 적용해 가중치를 얻고, 이를 Value에 곱해 **컨텍스트 벡터**를 만든다.  \n",
      "4. 여러 헤드가 독립적으로 이 과정을 수행하고, 결과를 concat 후 선형 변환한다.  \n",
      "\n",
      "이 과정을 여러 레이어에 걸쳐 반복함으로써, 모델은 **멀티‑레벨의 문맥**을 학습합니다.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. 미세조정 (Fine‑tuning) & RLHF\n",
      "\n",
      "사전학습만으로는 “사람이 원하는 방식”으로 응답하기 어렵습니다. 따라서 **인간 피드백**을 활용해 모델을 조정합니다.\n",
      "\n",
      "| 단계 | 내용 | 핵심 포인트 |\n",
      "|------|------|--------------|\n",
      "| **Supervised Fine‑tuning** | 인간이 직접 만든 질문‑답변 쌍(프롬프트‑응답)을 이용해 지도학습합니다. | 사전학습 모델을 초기 가중치로 사용하고, 일반적인 대화 형식에 맞게 손쉽게 적응시킵니다. |\n",
      "| **Reward Model (RM) 구축** | 여러 모델 응답을 인간 평가자(라벨러)가 **선호도**(예: “이 답변이 더 좋다”)로 평가합니다. 이를 기반으로 **Reward Model**을 학습합니다. | RM은 각 응답에 점수를 부여하는 스칼라 함수이며, “좋은 답변”에 높은 보상을 줍니다. |\n",
      "| **Reinforcement Learning from Human Feedback (RLHF)** | **Proximal Policy Optimization (PPO)** 같은 정책 최적화 알고리즘을 사용해, **Policy Model**(ChatGPT) 를 RM이 주는 보상을 최대화하도록 학습합니다. | - **KL‑penalty** 를 넣어 사전학습 정책과 크게 벗어나지 않게 제어 <br> - 여러 에피소드(대화)를 시뮬레이션하며 정책을 점진적으로 개선 |\n",
      "| **Safety & Alignment** | 부적절하거나 위험한 내용에 대한 **필터링**·**제어 토큰**·**시스템 프롬프트** 등을 추가해 안전성을 강화합니다. | “시스템 프롬프트”는 모델이 기본적인 행동 규칙을 따르게 하는 역할을 합니다. |\n",
      "\n",
      "#### RLHF 흐름 (요약)\n",
      "\n",
      "1. **초기 정책** = 사전학습 + supervised fine‑tuning 모델  \n",
      "2. **샘플 생성** → 여러 후보 응답을 생성  \n",
      "3. **인간 라벨링** → 어느 응답이 더 좋은지 평가 → 데이터셋 생성  \n",
      "4. **Reward Model 학습** → 인간 선호를 예측하도록 학습  \n",
      "5. **PPO** 로 정책 업데이트 → RM이 높은 보상을 주는 방향으로 파라미터 조정  \n",
      "6. **반복** (다수의 iteration) → 점진적으로 인간 의도에 부합하는 대화 능력 향상  \n",
      "\n",
      "---\n",
      "\n",
      "## 전체 학습 파이프라인 요약\n",
      "\n",
      "1. **데이터 → 토크나이징 → 대규모 사전학습** (다음 토큰 예측)  \n",
      "2. **사전학습 모델 → 지도식 미세조정** (질문‑답변 데이터)  \n",
      "3. **미세조정 모델 → 인간 평가 → Reward Model**  \n",
      "4. **Reward Model + PPO → RLHF** (정책 최적화)  \n",
      "5. **최종 모델** → 배포 (API, 챗봇 등) → 실시간 모니터링·피드백 루프 → 지속적인 업데이트  \n",
      "\n",
      "---\n",
      "\n",
      "## 왜 이런 복합 학습이 필요한가?\n",
      "\n",
      "| 목적 | 방법 | 이유 |\n",
      "|------|------|------|\n",
      "| **언어 이해·생성** | 사전학습 (대규모 텍스트) | 방대한 문맥 정보를 학습해 다양한 주제에 대해 자연스럽게 말할 수 있다. |\n",
      "| **특정 태스크 적합** | Supervised Fine‑tuning | 질문‑답변, 번역, 요약 등 구체적인 작업에 맞게 모델을 조정한다. |\n",
      "| **인간 친화성** | RLHF | 인간이 선호하는 답변 스타일·안전성을 반영한다. |\n",
      "| **안전·윤리** | 시스템 프롬프트·필터링 | 유해·편향된 출력을 억제한다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 기술적 상세 (선택적)\n",
      "\n",
      "- **학습 손실**: \\(\\mathcal{L} = -\\sum_{t=1}^{T}\\log p_{\\theta}(x_t|x_{<t})\\)  \n",
      "- **Optimizer**: AdamW (β₁=0.9, β₂=0.999, weight‑decay 0.01)  \n",
      "- **Learning‑rate schedule**: \\(\\eta_t = \\eta_{max} \\cdot \\min\\left(\\frac{t}{T_{warm}}, 1\\right) \\cdot (1 - \\frac{t}{T_{total}})^{\\alpha}\\) (보통 α≈1)  \n",
      "- **Batch size**: 0.5~2M 토큰 (GPU 메모리와 병렬도에 따라 조정)  \n",
      "- **Mixed‑precision (FP16/ BF16)**: 메모리 절감·학습 속도 향상  \n",
      "- **Gradient checkpointing**: 메모리 절약을 위해 중간 활성값을 재계산  \n",
      "\n",
      "---\n",
      "\n",
      "## 결론\n",
      "\n",
      "ChatGPT는 **대규모 텍스트를 통해 언어 패턴을 사전학습**하고, **인간 피드백을 활용한 강화학습**으로 “사람이 원하는 대답”에 맞게 미세조정됩니다. Transformer의 self‑attention 메커니즘이 핵심이며, 수십억~수조 개의 파라미터와 수조 개의 학습 토큰이 결합돼 현재 수준의 자연스러운 대화 능력을 구현합니다.  \n",
      "\n",
      "궁금한 점이 있으면 언제든 질문해 주세요!\n"
     ]
    }
   ],
   "source": [
    "# 2-튜플 형태의 메시지 목록으로 프롬프트 생성 (type, content)\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    # role, message\n",
    "    (\"system\", \"This system is an expert in answering questions about {topic}. Please provide clear and detailed explanations.\"),\n",
    "    (\"human\", \"{model_name} 모델의 학습 원리를 설명해 주세요.\"),\n",
    "])\n",
    "\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", model_name=\"ChatGPT\")\n",
    "print(messages)\n",
    "\n",
    "# 생성한 메시지를 바로 주입하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "print(type(response))\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      "## ChatGPT 모델이 학습되는 과정  \n",
      "(한국어로 자세히 설명합니다)\n",
      "\n",
      "### 1. 기본 개념\n",
      "- **대규모 언어 모델 (LLM)**: 수십억 개 이상의 파라미터를 가진 **Transformer** 기반 신경망.  \n",
      "- **목표**: 주어진 텍스트(문맥) 다음에 올 가장 가능성이 높은 토큰(단어 혹은 서브워드)을 예측하는 것.  \n",
      "- **학습 방식**: 크게 **사전 학습(Pre‑training)** → **미세 조정(Fine‑tuning)** → **강화 학습 기반 인간 피드백(RLHF)** 로 구분됩니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 사전 학습 (Pre‑training)\n",
      "\n",
      "### 2.1 데이터 수집 & 전처리\n",
      "| 단계 | 내용 |\n",
      "|------|------|\n",
      "| **데이터 소스** | 웹 페이지, 책, 위키피디아, 뉴스, 포럼 등 다양한 공개 텍스트. |\n",
      "| **크기** | 수백 GB ~ 수 TB 규모 (예: GPT‑4는 수조 토큰). |\n",
      "| **클리닝** | 저작권 침해, 개인 정보, 명백히 부적절한 내용 등을 필터링. |\n",
      "| **토크나이징** | **Byte‑Pair Encoding (BPE)** 혹은 **SentencePiece** 같은 서브워드 토크나이저를 사용해 텍스트를 **토큰**(보통 1~4개의 문자)으로 변환. 토크나이저는 전체 코퍼스에서 가장 빈번한 문자/문자열 쌍을 반복적으로 병합해 vocab(어휘집)을 만든다. |\n",
      "\n",
      "### 2.2 모델 아키텍처 – Transformer Decoder\n",
      "- **입력**: 토큰 시퀀스 `x₁, x₂, …, xₙ` (각 토큰은 정수 인덱스로 변환 후 임베딩 벡터로 매핑).  \n",
      "- **포지셔널 인코딩**: 순서 정보를 전달하기 위해 각 위치에 sinusoidal 혹은 학습 가능한 위치 임베딩을 더한다.  \n",
      "- **다중 헤드 셀프 어텐션**:  \n",
      "  \\[\n",
      "  \\text{Attention}(Q,K,V) = \\text{softmax}\\!\\left(\\frac{QK^{\\top}}{\\sqrt{d_k}}\\right)V\n",
      "  \\]\n",
      "  - `Q`, `K`, `V`는 각각 **Query**, **Key**, **Value** 행렬이며, 입력을 여러 헤드로 나눠 병렬 계산 후 다시 합친다.  \n",
      "  - **마스크드 어텐션**을 사용해 현재 토큰보다 뒤 토큰을 보지 못하게 함(오토레그레시브).  \n",
      "- **피드포워드 네트워크 (FFN)**: 각 토큰마다 독립적으로 적용되는 2‑layer MLP (`ReLU` 혹은 `GELU`).  \n",
      "- **잔차 연결 + 레이어 정규화**: 학습 안정성 및 깊은 네트워크 훈련을 돕는다.  \n",
      "\n",
      "### 2.3 학습 목표 – 언어 모델링 손실\n",
      "- **다음 토큰 예측 (Causal LM)**:  \n",
      "  \\[\n",
      "  \\mathcal{L} = -\\sum_{i=1}^{n}\\log P(x_i \\mid x_{<i})\n",
      "  \\]\n",
      "- **Cross‑entropy loss** 를 사용해 모델이 실제 토큰을 얼마나 높은 확률로 예측했는지 측정한다.  \n",
      "- **옵티마이저**: 일반적으로 **Adam** 혹은 **AdamW** (weight decay 포함) 사용.  \n",
      "- **학습 스케줄**:  \n",
      "  - **Warm‑up** 단계 → **Linear decay** 혹은 **Cosine decay**.  \n",
      "  - **배치 크기**: 수천~수만 토큰 (GPU/TPU 클러스터에서 병렬 처리).  \n",
      "- **분산 학습**: 데이터 병렬(다수의 GPU/TPU에 같은 모델 복제) + 모델 병렬(거대한 파라미터를 여러 장치에 분산) 기법을 결합.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 미세 조정 (Fine‑tuning)\n",
      "\n",
      "### 3.1 목적\n",
      "- **특정 도메인**(예: 법률, 의료) 혹은 **특정 작업**(예: 질문‑답변, 번역) 에 맞게 모델을 더 최적화한다.  \n",
      "- 사전 학습 단계에서는 “어떤 토큰이 올 가능성이 높은가”만 배웠지만, 실제 서비스에서는 **사용자 의도**와 **응답 품질**을 동시에 고려해야 한다.\n",
      "\n",
      "### 3.2 방법\n",
      "1. **Supervised Fine‑tuning**  \n",
      "   - **데이터**: `(입력, 기대 출력)` 쌍을 모은 **인스트럭션 데이터**(예: “다음 문장을 완성해 주세요”).  \n",
      "   - **손실**: 사전 학습과 동일하게 토큰‑레벨 cross‑entropy.  \n",
      "2. **Few‑shot / Prompt‑tuning**  \n",
      "   - 전체 파라미터를 고정하고 **프롬프트 토큰**(소수의 학습 가능한 임베딩)만 업데이트.  \n",
      "   - 파라미터 효율성을 크게 높인다.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 강화 학습 기반 인간 피드백 (RLHF)\n",
      "\n",
      "### 4.1 왜 RLHF가 필요한가?\n",
      "- **교차 엔트로피 손실**만으로는 “친절함”, “정확성”, “안전성” 같은 인간 수준의 품질을 직접 최적화하기 어렵다.  \n",
      "- 인간 평가자가 만든 **선호도**(어떤 응답이 더 좋은가)를 활용해 모델을 **보상 함수**에 맞게 조정한다.\n",
      "\n",
      "### 4.2 단계별 흐름\n",
      "\n",
      "| 단계 | 설명 |\n",
      "|------|------|\n",
      "| **1️⃣ SFT (Supervised Fine‑tuning)** | 앞서 설명한 supervised fine‑tuning을 수행해 기본적인 인스트럭션 수행 능력을 갖춘 모델을 만든다. |\n",
      "| **2️⃣ 데이터 수집** | 인간 라벨러가 동일한 프롬프트에 대해 **여러 개**의 모델 응답을 생성하고, **선호 순위**를 매긴다. |\n",
      "| **3️⃣ 보상 모델 (Reward Model, RM) 학습** | 라벨러의 순위를 **pairwise** 혹은 **ranking** 손실 (예: **Bradley‑Terry**, **Cross‑entropy over softmax of scores**) 로 학습해, **P(y|x)** 대신 **Rθ(x, y)** 라는 점수 함수를 만든다. |\n",
      "| **4️⃣ Proximal Policy Optimization (PPO) 등으로 정책 업데이트** | - **Policy**: 현재 LLM (파라미터 φ). <br> - **Reward**: RM이 제공하는 점수 Rθ. <br> - **목표**: 기대 보상 **E[Rθ]** 를 최대화하면서 기존 정책과 크게 달라지지 않도록 **KL‑penalty**(KL divergence) 를 적용한다. <br> - **PPO**는 작은 배치로 여러 번 샘플링하고, **advantage**(보상 - baseline) 를 계산해 정책을 업데이트한다. |\n",
      "| **5️⃣ 반복** | 새로운 라벨링, 보상 모델 재학습, PPO 업데이트를 여러 번 반복해 점진적으로 품질을 향상시킨다. |\n",
      "\n",
      "### 4.3 주요 특징\n",
      "- **Human‑in‑the‑loop**: 인간 라벨러가 직접 품질을 판단 → 모델이 “사람이 선호하는” 방향으로 학습.  \n",
      "- **Safety & Alignment**: 부적절하거나 위험한 출력을 억제하도록 보상 모델에 안전 관련 라벨을 포함한다.  \n",
      "- **샘플 효율성**: PPO는 기존 정책과 크게 차이나지 않는 작은 업데이트만 수행하므로, 대규모 파라미터를 가진 모델에서도 안정적으로 학습된다.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 추론 (Inference) 단계\n",
      "\n",
      "| 요소 | 설명 |\n",
      "|------|------|\n",
      "| **온도 (temperature)** | 0~1 사이 값. 0에 가깝게 하면 가장 확률이 높은 토큰만 선택 → 결정적 출력. 1에 가깝게 하면 다양성 ↑. |\n",
      "| **Top‑k / Top‑p (nucleus) 샘플링** | - **Top‑k**: 확률이 높은 k개의 토큰만 후보로 삼음.<br>- **Top‑p**: 누적 확률이 p (예: 0.9) 이하가 될 때까지 토큰을 포함. |\n",
      "| **시퀀스 길이** | 최대 토큰 수 (예: 4,096, 8,192 등)까지 연속적으로 생성. |\n",
      "| **Beam Search** (일부 상황) | 여러 후보 시퀀스를 동시에 탐색해 가장 높은 전체 로그 확률을 가진 문장을 선택. 일반적인 대화형 서비스에서는 주로 샘플링 기반 방법을 사용한다. |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 요약 흐름도\n",
      "\n",
      "```\n",
      "1️⃣ 데이터 수집 → 토크나이징 → 대규모 텍스트 코퍼스\n",
      "        |\n",
      "2️⃣ 사전 학습 (Transformer Decoder, Causal LM)\n",
      "        |\n",
      "3️⃣ Supervised Fine‑tuning (인스트럭션 데이터)\n",
      "        |\n",
      "4️⃣ 인간 피드백 수집 → 보상 모델 학습\n",
      "        |\n",
      "5️⃣ RLHF (PPO) → 정책(모델) 업데이트\n",
      "        |\n",
      "6️⃣ 최종 모델 배포 (온도, top‑p 등 샘플링 파라미터 조정)\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## 7. 핵심 포인트 정리\n",
      "\n",
      "| 핵심 요소 | 왜 중요한가? |\n",
      "|-----------|--------------|\n",
      "| **대규모 데이터** | 다양한 언어 패턴, 사실 지식, 문맥 이해를 학습. |\n",
      "| **Transformer 구조** | 셀프 어텐션으로 장거리 의존성을 효율적으로 모델링. |\n",
      "| **마스크드 어텐션** | 오토레그레시브(앞에서 뒤로) 생성 방식을 구현. |\n",
      "| **RLHF** | 인간이 기대하는 “유용함·친절함·안전함”을 모델에 직접 반영. |\n",
      "| **분산 학습** | 수십억 파라미터를 실제로 학습할 수 있게 함. |\n",
      "| **샘플링 전략** | 실제 서비스에서 다양하고 자연스러운 응답을 얻는 핵심. |\n",
      "\n",
      "---\n",
      "\n",
      "### 참고용 용어 정리\n",
      "| 용어 | 의미 |\n",
      "|------|------|\n",
      "| **Token** | 텍스트를 모델이 이해할 수 있는 최소 단위(보통 서브워드). |\n",
      "| **Embedding** | 토큰을 고정 차원의 실수 벡터로 변환. |\n",
      "| **Self‑Attention** | 입력 시퀀스 내부에서 각 토큰이 다른 토큰과 얼마나 연관되는지 학습. |\n",
      "| **KL‑penalty** | 정책 업데이트 시 기존 정책과의 차이를 제한하는 정규화 항. |\n",
      "| **PPO** | 정책 최적화 알고리즘 중 하나로, 작은 배치에서도 안정적인 업데이트가 가능. |\n",
      "| **Temperature** | 확률 분포를 “부드럽게” 만들거나 “뾰족하게” 만들고 싶을 때 조절. |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. 마무리\n",
      "\n",
      "ChatGPT는 **대규모 텍스트**를 **Transformer** 기반 모델에 **사전 학습**하고, **인스트럭션 데이터**와 **인간 피드백**을 활용해 **미세 조정**·**강화 학습**을 진행함으로써, 단순히 “다음 단어를 맞추는” 수준을 넘어 **사용자 의도에 맞는 유용하고 안전한** 응답을 생성할 수 있게 됩니다.  \n",
      "\n",
      "궁금한 점이 더 있으면 언제든 물어보세요!\n"
     ]
    }
   ],
   "source": [
    "# 체인을 생성하여 호출하기\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "chain = chat_prompt | llm | StrOutputParser()\n",
    "\n",
    "response = chain.invoke({\"topic\":\"AI\", \"model_name\":\"ChatGPT\"})\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) ChatPromptTemplate\n",
    "* SystemMessagePromptTemplate와 HumanMessagePromptTemplate 클래스 사용\n",
    "* 객체 지향적 접근 - Message 객체를 독립적으로 생성 가능\n",
    "* 여러 조건에 따라 다른 시스템 메시지 선택\n",
    "\n",
    "```python\n",
    "if user_is_beginner:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"초보자를 위한 설명: {topic}\")\n",
    "else:\n",
    "    system_message = SystemMessagePromptTemplate.from_template(\"전문가를 위한 상세 분석: {topic}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Deep learning** is a sub‑field of machine learning (and, by extension, artificial intelligence) that focuses on algorithms called *artificial neural networks*—especially deep neural networks with many layers. These networks are inspired loosely by the structure and function of the human brain, though they are far simpler and mathematically defined.\n",
      "\n",
      "Below is a step‑by‑step overview of what deep learning is, how it works, and why it matters.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. The Big Picture\n",
      "\n",
      "| Concept | Relationship |\n",
      "|---------|--------------|\n",
      "| **Artificial Intelligence (AI)** | The broad goal of creating machines that can perform tasks that normally require human intelligence (reasoning, perception, language, etc.). |\n",
      "| **Machine Learning (ML)** | A subset of AI that gives computers the ability to learn from data rather than being explicitly programmed. |\n",
      "| **Deep Learning (DL)** | A subset of ML that uses deep (many‑layered) neural networks to automatically learn hierarchical representations of data. |\n",
      "\n",
      "So, deep learning ≈ “neural networks with many layers that learn directly from raw data.”\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Core Building Block: The Artificial Neuron\n",
      "\n",
      "A **neuron** (or *node*) computes a simple function:\n",
      "\n",
      "\\[\n",
      "a = \\sigma\\!\\left(\\sum_{i=1}^{n} w_i x_i + b\\right)\n",
      "\\]\n",
      "\n",
      "- **\\(x_i\\)** – inputs (features or outputs of previous neurons)  \n",
      "- **\\(w_i\\)** – learnable weights (strength of each connection)  \n",
      "- **\\(b\\)** – bias term (shifts the activation)  \n",
      "- **\\(\\sigma\\)** – *activation function* (e.g., ReLU, sigmoid, tanh) that adds non‑linearity.\n",
      "\n",
      "A **layer** is a collection of neurons that operate in parallel on the same input vector. Stacking layers yields a **network**.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. What Makes a Network “Deep”?\n",
      "\n",
      "- **Depth** = number of *hidden* layers (layers between the input and output).  \n",
      "- **Shallow network**: 1–2 hidden layers.  \n",
      "- **Deep network**: 3+ hidden layers; modern models often have dozens, hundreds, or even thousands of layers.\n",
      "\n",
      "**Why depth matters?**  \n",
      "Each layer can learn increasingly abstract features:\n",
      "\n",
      "| Layer | Typical Feature (e.g., image) |\n",
      "|-------|------------------------------|\n",
      "| 1 (low‑level) | Edges, corners |\n",
      "| 2 | Textures, simple shapes |\n",
      "| 3 | Object parts (e.g., wheels, eyes) |\n",
      "| 4+ (high‑level) | Whole objects, scenes, concepts |\n",
      "\n",
      "This hierarchical representation is what gives deep learning its power.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Training a Deep Neural Network\n",
      "\n",
      "1. **Define a loss (cost) function** that measures how far the network’s predictions are from the true targets (e.g., cross‑entropy for classification, mean‑squared error for regression).\n",
      "\n",
      "2. **Forward pass**: Input data flows through the network, producing predictions.\n",
      "\n",
      "3. **Backward pass (back‑propagation)**:  \n",
      "   - Compute the gradient of the loss w.r.t. every weight using the chain rule.  \n",
      "   - Propagate errors from the output layer back to earlier layers.\n",
      "\n",
      "4. **Weight update**: Apply an optimizer (SGD, Adam, RMSprop, etc.) that adjusts the weights in the direction that reduces loss.\n",
      "\n",
      "5. **Iterate** over many *epochs* (full passes through the training set) until the loss stabilizes or validation performance stops improving.\n",
      "\n",
      "### Key Techniques that Make Training Feasible\n",
      "\n",
      "| Technique | Why it’s needed |\n",
      "|-----------|-----------------|\n",
      "| **Activation functions** (ReLU, Leaky ReLU) | Prevent vanishing gradients, speed up convergence |\n",
      "| **Batch normalization** | Stabilizes learning by normalizing layer inputs |\n",
      "| **Dropout / Stochastic depth** | Regularizes the model, reduces overfitting |\n",
      "| **Weight initialization schemes** (He, Xavier) | Start training in a “good” region of parameter space |\n",
      "| **Learning‑rate schedules** (cosine decay, warm‑up) | Adjust step size during training for better convergence |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Major Architectures & Their Domains\n",
      "\n",
      "| Architecture | Typical Use‑Case | Key Idea |\n",
      "|--------------|------------------|----------|\n",
      "| **Convolutional Neural Networks (CNNs)** | Image & video analysis, medical imaging, speech spectrograms | Learn spatially local patterns via convolution filters |\n",
      "| **Recurrent Neural Networks (RNNs)** (LSTM, GRU) | Sequential data: language, time series, audio | Maintain hidden state across time steps |\n",
      "| **Transformer** | Natural language processing, vision (ViT), multimodal tasks | Self‑attention mechanism replaces recurrence, enabling parallel processing |\n",
      "| **Autoencoders & Variational Autoencoders (VAEs)** | Dimensionality reduction, generative modeling, anomaly detection | Learn to compress and reconstruct data |\n",
      "| **Generative Adversarial Networks (GANs)** | Image synthesis, style transfer, data augmentation | Two networks (generator & discriminator) compete, producing realistic samples |\n",
      "| **Graph Neural Networks (GNNs)** | Data on graphs (social networks, molecules) | Propagate information along edges of a graph |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Why Deep Learning Works So Well\n",
      "\n",
      "1. **Representation learning** – Networks discover features automatically, eliminating the need for handcrafted descriptors.\n",
      "2. **Scalability** – With enough data and compute, larger models keep improving (the “scaling laws” observed in language models, for example).\n",
      "3. **End‑to‑end training** – The same loss drives the entire system, aligning all parts toward the final objective.\n",
      "4. **Hardware acceleration** – GPUs, TPUs, and specialized ASICs make massive matrix multiplications fast.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. Common Misconceptions\n",
      "\n",
      "| Misconception | Reality |\n",
      "|---------------|---------|\n",
      "| “Deep learning *understands* images like humans.” | It learns statistical patterns; it can be fooled by adversarial perturbations and lacks true semantics. |\n",
      "| “More layers always = better.” | After a point, depth can cause overfitting, vanishing gradients, or unnecessary compute; architecture design matters. |\n",
      "| “Training a deep net is just about throwing data at it.” | Data quality, preprocessing, hyper‑parameter tuning, and regularization are crucial. |\n",
      "| “Deep learning replaces all other ML methods.” | For small datasets or tabular data, classical methods (e.g., gradient boosting) often outperform deep nets. |\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Practical Workflow (High‑Level)\n",
      "\n",
      "1. **Problem definition** – classification, regression, segmentation, etc.  \n",
      "2. **Data collection & labeling** – ensure diversity, balance, and sufficient volume.  \n",
      "3. **Preprocessing** – normalization, augmentation, tokenization (for text), etc.  \n",
      "4. **Model selection** – choose an architecture suited to the data (CNN for images, Transformer for text, etc.).  \n",
      "5. **Training** – split data (train/val/test), monitor metrics, use early stopping.  \n",
      "6. **Evaluation** – confusion matrix, ROC‑AUC, BLEU, etc., depending on task.  \n",
      "7. **Deployment** – export to ONNX/TFLite, serve via APIs, consider latency & memory constraints.  \n",
      "8. **Monitoring & maintenance** – watch for data drift, retrain when performance degrades.\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Current Frontiers (as of 2024‑2025)\n",
      "\n",
      "- **Foundation models** (e.g., GPT‑4, PaLM‑2, Stable Diffusion) – massive, pre‑trained models fine‑tuned for many downstream tasks.  \n",
      "- **Multimodal learning** – models that jointly process text, images, audio, and video (e.g., CLIP, Flamingo).  \n",
      "- **Efficient inference** – quantization, pruning, and distillation to run large models on edge devices.  \n",
      "- **Neurosymbolic AI** – combining deep learning with symbolic reasoning for better interpretability and logic.  \n",
      "- **Self‑supervised learning** – learning useful representations from unlabeled data (e.g., masked language modeling, contrastive learning).  \n",
      "\n",
      "---\n",
      "\n",
      "## 10. Quick Takeaway\n",
      "\n",
      "- **Deep learning = deep neural networks** that automatically learn hierarchical features from raw data.  \n",
      "- It shines when you have **large datasets** and **computational resources**.  \n",
      "- The core loop is **forward pass → loss → back‑propagation → weight update**.  \n",
      "- A rich ecosystem of **architectures, training tricks, and hardware** makes it practical for vision, language, speech, graphs, and more.  \n",
      "\n",
      "If you’d like to dive deeper into any specific architecture (e.g., Transformers) or see a concrete code example (PyTorch/TensorFlow), just let me know!\n"
     ]
    }
   ],
   "source": [
    "# ChatMessagePromptTemplate 활용\n",
    "\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatMessagePromptTemplate\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 개별 메시지 템플릿 정의\n",
    "system_message = SystemMessagePromptTemplate.from_template(\n",
    "    \"You are an AI expert in {topic}. Please provide clear and detailed explanations.\"\n",
    ")\n",
    "user_message = HumanMessagePromptTemplate.from_template(\n",
    "    \"{question}\"\n",
    ")\n",
    "ai_message = AIMessagePromptTemplate.from_template(\n",
    "    \"This is an example answer about {topic}.\"\n",
    ")\n",
    "\n",
    "# ChatPromptTemplate로 메시지들을 묶기\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    system_message,\n",
    "    user_message,\n",
    "    ai_message\n",
    "])\n",
    "\n",
    "# 메시지 생성\n",
    "messages = chat_prompt.format_messages(topic=\"AI\", question=\"What is deep learning?\")\n",
    "\n",
    "# LLM 호출\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "response = llm.invoke(messages)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ChatMessagePromptTemplate는 여러 종류의 메시지(시스템, 인간, AI)를 조합하여 복잡한 프롬프트를 생성할 때 유용합니다.\n",
    "* SystemMessagePromptTemplate: 이 템플릿은 AI 모델에게 역할을 부여하거나 전반적인 규칙을 설정하는 시스템 메시지를 만듭니다. 위의 예시에서는 \"번역을 도와주는 유용한 도우미\"라는 역할을 지정합니다.\n",
    "* HumanMessagePromptTemplate: 이 템플릿은 사용자의 질문이나 요청을 담는 인간 메시지를 만듭니다. 아래의 예시에서는 번역할 텍스트를 입력받습니다.\n",
    "* ChatPromptTemplate.from_messages: 이 클래스 메서드는 시스템 메시지, 인간 메시지 등 여러 종류의 MessagePromptTemplate 객체들을 리스트로 받아 하나의 채팅 프롬프트 템플릿으로 통합합니다.\n",
    "* format_messages: 이 메서드는 정의된 템플릿에 실제 값을 채워 넣어 [SystemMessage, HumanMessage] 형태의 리스트를 반환합니다. 이 리스트는 채팅 모델(Chat Model) 에 바로 전달될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful assistant that translates English to Korean.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I love programming.', additional_kwargs={}, response_metadata={})]\n",
      "나는 프로그래밍을 사랑해요.\n"
     ]
    }
   ],
   "source": [
    "# 필요한 라이브러리 임포트\n",
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "# 1. SystemMessagePromptTemplate와 HumanMessagePromptTemplate 생성\n",
    "# SystemMessagePromptTemplate는 모델의 페르소나 또는 기본 지침을 설정합니다.\n",
    "system_template = \"You are a helpful assistant that translates {input_language} to {output_language}.\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_template)\n",
    "\n",
    "# HumanMessagePromptTemplate는 사용자로부터 받는 입력 프롬프트를 정의합니다.\n",
    "human_template = \"{text_to_translate}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "\n",
    "# 2. ChatPromptTemplate 생성\n",
    "# 위에서 만든 두 템플릿을 리스트로 묶어 ChatPromptTemplate을 만듭니다.\n",
    "chat_prompt_template = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "# 3. 프롬프트 포맷팅\n",
    "# chat_prompt_template.format_messages()를 사용하여 최종 메시지 리스트를 생성합니다.\n",
    "# 이 함수는 딕셔너리 형태의 입력 변수를 받습니다.\n",
    "formatted_prompt = chat_prompt_template.format_messages(\n",
    "    input_language=\"English\",\n",
    "    output_language=\"Korean\",\n",
    "    text_to_translate=\"I love programming.\"\n",
    ")\n",
    "\n",
    "# 4. 결과 출력\n",
    "print(formatted_prompt)\n",
    "\n",
    "# LLM 호출\n",
    "response = llm.invoke(formatted_prompt)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4) FewShotPromptTemplate\n",
    "* FewShotPromptTemplate은 모델이 특정 형식을 따르게 하거나, 일관된 응답을 생성하도록 유도할 때 유용합니다.\n",
    "* 도메인 지식이 필요하거나, AI가 오답을 줄이고 더 신뢰할 만한 답변을 생성하도록 해야 할 때 효과적입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-1) PromptTemplate을 사용하지 않는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "## 태양계 행성 개요 (간략 정리)\n",
      "\n",
      "| 순서 | 행성 | 종류 | 평균 거리(태양으로부터) | 주요 특징 |\n",
      "|------|------|------|------------------------|-----------|\n",
      "| 1 | **수성 (Mercury)** | 암석행성 | 0.39 AU (약 5.8 백만 km) | 가장 작은·가장 뜨거운(낮)·극심한 온도 차 |\n",
      "| 2 | **금성 (Venus)** | 암석행성 | 0.72 AU (약 1.08 억 km) | 두꺼운 이산화탄소 대기·극강 온실효과·자전이 역행 |\n",
      "| 3 | **지구 (Earth)** | 암석행성 | 1 AU (약 1.5 억 km) | 물·대기·생명 존재, 자기장이 강함 |\n",
      "| 4 | **화성 (Mars)** | 암석행성 | 1.52 AU (약 2.28 억 km) | 얇은 이산화탄소 대기·극지에 물 얼음·과거 물 흐름 흔적 |\n",
      "| 5 | **목성 (Jupiter)** | 가스행성 | 5.20 AU (약 7.78 억 km) | 가장 큰 행성·강력한 자기장·대적점(거대한 폭풍)·다수의 위성 |\n",
      "| 6 | **토성 (Saturn)** | 가스행성 | 9.58 AU (약 1.43 억 km) | 눈에 띄는 고리 시스템·다수의 위성(특히 타이탄) |\n",
      "| 7 | **천왕성 (Uranus)** | 얼음거대행성 | 19.2 AU (약 2.87 억 km) | 자전축이 98° 기울어져 ‘옆으로 누운’ 형태·청청색 대기 |\n",
      "| 8 | **해왕성 (Neptune)** | 얼음거대행성 | 30.1 AU (약 4.5 억 km) | 가장 바람이 강한 행성·청청색 대기·트라이톤 위성(역행 궤도) |\n",
      "\n",
      "### 주요 포인트\n",
      "- **암석행성**(수성·금성·지구·화성)은 고체 표면을 가지고 있으며, 태양에 가까울수록 크기가 작다.  \n",
      "- **가스행성**(목성·토성)은 주로 수소·헬륨으로 이루어져 있고, 거대한 대기와 강력한 자기장을 가진다.  \n",
      "- **얼음거대행성**(천왕성·해왕성)은 수소·헬륨 외에 물, 메탄, 암모니아 등 ‘얼음’ 물질이 많이 포함돼 있다.  \n",
      "- 행성들의 **공전 궤도**는 거의 원에 가깝지만, 각각 약간의 이심률을 가지고 있다.  \n",
      "- **위성**도 다양: 지구는 달 하나, 목성·토성은 수십 개, 해왕성은 트라이톤 같은 특이 위성을 가진다.  \n",
      "\n",
      "이 정도면 태양계 행성들의 기본적인 특징을 한눈에 파악하실 수 있을 겁니다! 필요하시면 각 행성에 대한 더 자세한 정보도 알려드릴게요.\n"
     ]
    }
   ],
   "source": [
    "# PromptTemplate을 사용하지 않는 경우\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"태양계의 행성들을 간략히 정리해 주세요.\")\n",
    "\n",
    "print(type(result))\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4-2) FewShotChatMessagePromptTemplate 사용하는 경우"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first=ChatPromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.'), additional_kwargs={}), FewShotChatMessagePromptTemplate(examples=[{'input': '뉴턴의 운동 법칙을 요약해 주세요.', 'output': '### 뉴턴의 운동 법칙\\n1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\\n2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\\n3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.'}, {'input': '지구의 대기 구성 요소를 알려주세요.', 'output': '### 지구 대기의 구성\\n- **질소 (78%)**: 대기의 대부분을 차지합니다.\\n- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\\n- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\\n- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})])), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})]) middle=[] last=ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x00000278346027B0>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x0000027834555280>, root_client=<openai.OpenAI object at 0x00000278344FA690>, root_async_client=<openai.AsyncOpenAI object at 0x0000027834590650>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "### 태양계의 행성\n",
      "1. **수성**: 가장 작은 행성, 태양과 가장 가깝습니다.\n",
      "2. **금성**: 온도가 매우 높은 행성입니다.\n",
      "3. **지구**: 생명체가 사는 유일한 행성입니다.\n",
      "4. **화성**: 붉은 행성으로, 로봇 탐사가 활발합니다.\n",
      "5. **목성**: 태양계에서 가장 큰 행성입니다.\n",
      "6. **토성**: 아름다운 고리를 가진 행성입니다.\n",
      "7. **천왕성**: 자전축이 기울어져 있습니다.\n",
      "8. **해왕성**: 가장 먼 행성입니다.\n"
     ]
    }
   ],
   "source": [
    "# FewShotChatMessagePromptTemplate 사용하는 경우\n",
    "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"뉴턴의 운동 법칙을 요약해 주세요.\",\n",
    "        \"output\": \"\"\"### 뉴턴의 운동 법칙\n",
    "1. **관성의 법칙**: 힘이 작용하지 않으면 물체는 계속 같은 상태를 유지합니다.\n",
    "2. **가속도의 법칙**: 물체에 힘이 작용하면, 힘과 질량에 따라 가속도가 결정됩니다.\n",
    "3. **작용-반작용 법칙**: 모든 힘에는 크기가 같고 방향이 반대인 힘이 작용합니다.\"\"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"지구의 대기 구성 요소를 알려주세요.\",\n",
    "        \"output\": \"\"\"### 지구 대기의 구성\n",
    "- **질소 (78%)**: 대기의 대부분을 차지합니다.\n",
    "- **산소 (21%)**: 생명체가 호흡하는 데 필요합니다.\n",
    "- **아르곤 (0.93%)**: 반응성이 낮은 기체입니다.\n",
    "- **이산화탄소 (0.04%)**: 광합성 및 온실 효과에 중요한 역할을 합니다.\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 예제 프롬프트 템플릿\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# FewShotChatMessagePromptTemplate 적용\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples,\n",
    ")\n",
    "\n",
    "# 최종 프롬프트 구성\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"당신은 초등학생도 쉽게 이해할 수 있도록 쉽게 설명하는 과학 교육자입니다.\"),\n",
    "        few_shot_prompt,\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 모델 생성 및 체인 구성\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "chain = final_prompt | llm\n",
    "print(chain)\n",
    "\n",
    "# 테스트 실행\n",
    "result = chain.invoke({\"input\": \"태양계의 행성들을 간략히 정리해 주세요.\"})\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-1) PartialPrompt \n",
    "* 프롬프트를 더 동적으로 활용할 수 있으며, AI 응답을 더 일관성 있게 조정 가능함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 가을에 일어나는 대표적인 지구과학 현상은 태풍 발생이 맞나요? 가을에 주로 발생하는 지구과학 현상을 3개 알려주세요\n",
      " 모델 응답: 가을에 주로 발생하는 지구과학 현상 3개는 다음과 같습니다.\n",
      "\n",
      "1.  **태풍 발생**: 태풍은 7월부터 10월까지 발생하며, 가을에 해당하는 9월과 10월에 태풍이 많이 발생합니다.\n",
      "2.  **성층권 오존층의 회복**: 오존층은 자외선에 의해 파괴되며, 성층권에서 오존 분자가 자외선을 흡수하여 지구 표면으로의 자외선 도달을 막는 역할을 합니다. \n",
      "3.  **일교차 증가**: 가을이 되면서 낮과 밤의 길이가 짧아지고, 기온 차이가 커지면서 일교차가 증가합니다. 이는 지구가 자전하면서 태양과의 거리가 멀어지기 때문입니다. 일교차는 낮과 밤의 기온 차이를 의미하며, 지구의 자전과 태양과의 거리 변화로 인해 발생합니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# 프롬프트 템플릿 정의 (부분 변수 적용)\n",
    "prompt = PromptTemplate(\n",
    "    template=\"{season}에 일어나는 대표적인 지구과학 현상은 {phenomenon}이 맞나요? {season}에 주로 발생하는 지구과학 현상을 3개 알려주세요\",\n",
    "    input_variables=[\"phenomenon\"],  # 사용자 입력 필요\n",
    "    partial_variables={\"season\": get_current_season()}  # 동적으로 계절 값 할당\n",
    ")\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "\n",
    "# 특정 계절의 현상 질의\n",
    "query = prompt.format(phenomenon=\"태풍 발생\")\n",
    "result = llm.invoke(query)\n",
    "\n",
    "\n",
    "# 결과 출력\n",
    "print(f\" 프롬프트: {query}\")\n",
    "print(f\" 모델 응답: {result.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 계절: 가을\n",
      "\n",
      " 가을에 발생하는 자연 현상:\n",
      "가을에 주로 발생하는 대표적인 지구과학 현상 3가지는 다음과 같습니다.\n",
      "\n",
      "1.  **북극광(Aurora Borealis)**: 북극광은 북극 지역에서 발생하는 아름다운 빛의 현상입니다. 태양풍이 지구 자기장에 부딪혀 발생하며, 주로 가을과 겨울에 북극 지역에서 볼 수 있습니다. 북극광은 녹색, 빨간색, 보라색 등 다양한 색상으로 나타납니다.\n",
      "\n",
      "2.  **블루문(Blue Moon)**: 블루문은 달이 한 달에 두 번 뜨는 현상으로, 달의 주기와 지구의 자전 주기가 맞지 않아 발생합니다. 블루문은 가을에 자주 발생하며, 달이 더 크고 밝게 보입니다.\n",
      "\n",
      "3.  **유성우(Meteor Shower)**: 유성우는 밤하늘에 별똥이 떨어지는 현상으로, 지구가 혜성이나 소행성의 궤도를 통과할 때 발생합니다. 가을에는 페르세우스 유성우, 오리온 유성우 등 다양한 유성우가 발생합니다. 유성우는 밤하늘을 아름답게 장식하며, 운이 좋으면 많은 별똥을 볼 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 계절을 결정하는 함수 (남반구/북반구 고려)\n",
    "def get_current_season(hemisphere=\"north\"):\n",
    "    month = datetime.now().month\n",
    "\n",
    "    if hemisphere == \"north\":  # 북반구 (기본값)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"봄\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"여름\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"가을\"\n",
    "        else:\n",
    "            return \"겨울\"\n",
    "    else:  # 남반구 (계절 반대)\n",
    "        if 3 <= month <= 5:\n",
    "            return \"가을\"\n",
    "        elif 6 <= month <= 8:\n",
    "            return \"겨울\"\n",
    "        elif 9 <= month <= 11:\n",
    "            return \"봄\"\n",
    "        else:\n",
    "            return \"여름\"\n",
    "\n",
    "# Step 1: 현재 계절 결정\n",
    "season = get_current_season(\"north\")  # 계절 값 얻기\n",
    "print(f\"현재 계절: {season}\")\n",
    "\n",
    "# Step 2: 해당 계절의 자연 현상 추천\n",
    "prompt2 = ChatPromptTemplate.from_template(\n",
    "    \"{season}에 주로 발생하는 대표적인 지구과학 현상 3가지를 알려주세요. \"\n",
    "    \"각 현상에 대해 간단한 설명을 포함해주세요.\"\n",
    ")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.0)\n",
    "llm = ChatOpenAI(\n",
    "    #api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.0\n",
    ")\n",
    "\n",
    "# 체인 2: 자연 현상 추천 (입력: 계절 → 출력: 자연 현상 목록)\n",
    "chain2 = (\n",
    "    {\"season\": lambda x : season}  # chain1의 출력을 season 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: 현재 계절에 따른 자연 현상 추천\n",
    "response = chain2.invoke({})\n",
    "print(f\"\\n {season}에 발생하는 자연 현상:\\n{response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-2) PartialPrompt \n",
    "* API 호출 데이터, 시간 정보, 사용자 정보 등을 반영할 때 매우 유용함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 프롬프트: 현재 1달러 = 1377.98원 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\n",
      " 모델 응답: ## 현행 환율: 1달러 = 1377.98원\n",
      "\n",
      "### **주요 분석 포인트**\n",
      "\n",
      "*   **원달러 환율 상승**: 1377.98원이라는 수치는 최근 몇 년간 꾸준히 상승한 결과입니다. \n",
      "*   **글로벌 경제 요인**: 미국 연방준비제도(Fed)의 금리 인상 사이클, 글로벌 경기침체 우려, 주요 수출국의 경기 부진 등이 원달러 환율 상승에 영향을 미치고 있습니다. \n",
      "*   **국내 경제 요인**: 한국의 무역수지 적자, 외국인 투자 자금 유출, 가계 부채 증가 등도 원화 약세 요인으로 작용하고 있습니다.\n",
      "\n",
      "### **환율 전망**\n",
      "\n",
      "*   **상승 지속 가능성**: 미국의 강력한 경기 지표와 고금리 장기화 가능성으로 인해 당분간 원달러 환율이 1350원대를 돌파할 가능성이 있습니다.\n",
      "*   **하락 가능성**: 한국의 수출 증가세 회복, 외국인 투자 자금 유입 확대, 글로벌 경기 회복 시 원달러 환율이 하락할 가능성도 있습니다.\n",
      "\n",
      "### **투자 및 생활에 미치는 영향**\n",
      "\n",
      "*   **수출 기업**: 원달러 환율 상승은 수출 기업의 수익성 개선에 긍정적 영향을 미칠 수 있습니다. \n",
      "*   **수입 기업 및 소비자**: 수입 기업과 소비자는 원화 약세로 인해 수입 비용 증가, 물가 상승 등에 부정적인 영향을 받을 수 있습니다.\n",
      "\n",
      "### **대응 전략**\n",
      "\n",
      "*   **기업**: 환율 변동 위험 관리, 수출입 계약 조건 검토, 환헤지 전략 수립 등 필요합니다. \n",
      "*   **개인**: 환율 변동에 따른 투자 전략 조정, 외화 자산 포트폴리오 관리, 환율 변동 위험에 대비한 자산 배분 전략 세우는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# 실시간 환율을 가져오는 함수\n",
    "def get_exchange_rate():\n",
    "    response = requests.get(\"https://api.exchangerate-api.com/v4/latest/USD\")\n",
    "    data = response.json()\n",
    "    return f\"1달러 = {data['rates']['KRW']}원\"\n",
    "\n",
    "# Partial Prompt 활용\n",
    "prompt = PromptTemplate(\n",
    "    template=\"현재 {info} 기준으로 환율 정보를 알려드립니다. 이에 대한 분석을 제공해 주세요.\",\n",
    "    input_variables=[],  # 사용자 입력 없음\n",
    "    partial_variables={\"info\": get_exchange_rate()}  # API에서 가져온 데이터 자동 반영\n",
    ")\n",
    "\n",
    "# LLM 모델 설정\n",
    "#llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.0)\n",
    "\n",
    "# 모델에 프롬프트 전달 및 응답 받기\n",
    "response = llm.invoke(prompt.format())\n",
    "\n",
    "# 결과 출력\n",
    "print(\" 프롬프트:\", prompt.format())\n",
    "print(\" 모델 응답:\", response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
