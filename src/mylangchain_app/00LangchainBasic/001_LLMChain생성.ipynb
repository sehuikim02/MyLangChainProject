{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a",
   "metadata": {
    "id": "ed0f96f1-910f-438f-876f-9eff119c2b0a"
   },
   "source": [
    "### LLM Chain 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9",
   "metadata": {
    "id": "5a5b1e2f-9d67-4d01-9a8c-83ced6b711a9"
   },
   "source": [
    "## 1. 환경 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81",
   "metadata": {
    "id": "b03b7854-f96a-47fc-b3c7-b2bdfb55df81"
   },
   "source": [
    "### 1) 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cd87a33-0a37-461b-8f37-3c142e60b1f6",
    "outputId": "c96ed02d-19b7-4e90-d92e-1ae52895e303"
   },
   "outputs": [],
   "source": [
    "# poetry add python-dot/env langchain langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55152049-e9e5-4952-8e19-409f58cf3ac9",
   "metadata": {
    "id": "55152049-e9e5-4952-8e19-409f58cf3ac9"
   },
   "source": [
    "### 2) OpenAI 인증키 설정\n",
    "https://openai.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76f68a8-4745-4377-8057-6090b87377d1",
   "metadata": {
    "id": "b76f68a8-4745-4377-8057-6090b87377d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gsk_X\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='.env')\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09aaca6-5aa2-4b52-bbfc-196e808dc5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.27\n"
     ]
    }
   ],
   "source": [
    "import langchain\n",
    "print(langchain.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c",
   "metadata": {
    "id": "fc01c50a-32cf-49af-891a-f9b17fa0bd6c"
   },
   "source": [
    "## 2. LLM Chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23729d10-9600-415b-b7d1-f954665224e3",
   "metadata": {
    "id": "23729d10-9600-415b-b7d1-f954665224e3"
   },
   "source": [
    "### 1) Prompt + LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "on0y4xF8VoyE",
   "metadata": {
    "id": "on0y4xF8VoyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.messages.ai.AIMessage'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# model\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model = \"openai/gpt-oss-120b\",                # GPT-OSS-120B\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 실행\n",
    "result = llm.invoke(\"인공지능 모델의 학습 원리에 대하여 쉽게 설명해 주세요.\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc4accf-c927-40a3-ba2c-f891c94c34f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='## 인공지능 모델, 특히 **머신러닝·딥러닝** 모델이 어떻게 배우는지 쉽게 풀어볼게요.\\n\\n---\\n\\n## 1. 기본 아이디어: “경험을 통해 규칙을 찾는다”\\n\\n- **인간**: 아이가 사과와 바나나를 여러 번 보여주면서 “이건 사과, 저건 바나나”라고 알려주면, 나중에 새로운 과일을 보면 어느 쪽에 가까운지 스스로 판단하게 돼요.\\n- **AI 모델**: 컴퓨터에게도 같은 “경험(데이터)”을 많이 주면, 스스로 “어떤 입력이 어떤 결과와 연결되는지”를 찾아냅니다.\\n\\n---\\n\\n## 2. 구성 요소\\n\\n| 요소 | 설명 | 비유 |\\n|------|------|------|\\n| **데이터** | 모델이 학습할 때 보는 예시(이미지, 텍스트, 소리 등) | 아이가 보는 그림책 |\\n| **모델(네트워크)** | 입력을 받아서 출력을 만드는 수식·구조(뉴런·가중치) | 아이의 뇌 속 회로망 |\\n| **가중치(파라미터)** | 모델이 학습하면서 조정하는 숫자들 | 뇌 속 시냅스 강도 |\\n| **손실 함수(Loss)** | 모델이 만든 답과 정답 사이의 차이를 수치화 | “얼마나 틀렸는지 점수” |\\n| **최적화 알고리즘** | 가중치를 조금씩 바꿔 손실을 줄이는 방법 | “점수를 낮추려는 연습” |\\n\\n---\\n\\n## 3. 학습 과정 (한 번의 **epoch** 예시)\\n\\n1. **데이터를 하나씩 꺼낸다**  \\n   예) 고양이 사진 + “고양이” 라는 라벨을 가져옴.\\n\\n2. **모델에 입력한다**  \\n   사진을 네트워크에 넣으면, 현재 가중치에 따라 “고양이일 확률”을 출력.\\n\\n3. **손실을 계산한다**  \\n   - 모델이 0.7(70%)이라고 예측했는데 실제 정답은 1(100%) → 손실이 발생.\\n   - 손실 함수(예: 교차 엔트로피)로 “얼마나 틀렸는지” 수치화.\\n\\n4. **가중치를 업데이트한다**  \\n   - **역전파(backpropagation)** 라는 과정으로, 손실이 큰 방향(오차가 큰 부분)을 찾아 가중치를 조금씩 조정.\\n   - **경사 하강법(Gradient Descent)** 은 “오차가 가장 크게 줄어드는 방향으로 한 걸음씩 움직이는” 방법.\\n\\n5. **전체 데이터를 다 돌면 한 번의 epoch**  \\n   - 여러 epoch를 반복하면서 가중치가 점점 최적에 가까워짐.\\n\\n---\\n\\n## 4. 비유로 이해하기\\n\\n### “산을 오르는 등산가” 비유\\n- **산** = 손실 함수가 만든 “오차 지형”. 가장 낮은 곳(밑바닥)이 최적점.\\n- **등산가** = 최적화 알고리즘(경사 하강법). 현재 위치에서 가장 가파른 아래쪽을 찾아 한 걸음씩 내려감.\\n- **여러 번 반복** = 여러 epoch. 등산가가 여러 번 산을 오르내리며 최저점(최적 가중치)을 찾음.\\n\\n### “요리 레시피 조정” 비유\\n- **재료와 양** = 가중치.\\n- **맛(정답과의 차이)** = 손실.\\n- **시식 후 조정** = 역전파와 가중치 업데이트.\\n- **반복** = 레시피를 여러 번 고쳐가며 최고의 맛을 찾음.\\n\\n---\\n\\n## 5. 딥러닝(신경망)에서 특별히 중요한 점\\n\\n| 특징 | 설명 |\\n|------|------|\\n| **다층 구조** | 여러 층을 쌓아 복잡한 패턴을 단계별로 추출 (예: 가장자리 → 형태 → 물체) |\\n| **비선형 활성함수** | ReLU, Sigmoid 등으로 복잡한 관계를 표현 |\\n| **대량 데이터** | 데이터가 많을수록 일반화가 잘돼서 실제 상황에서도 잘 동작 |\\n| **GPU 가속** | 수천·수만 개의 가중치를 빠르게 계산해 학습 속도 향상 |\\n\\n---\\n\\n## 6. 간단한 예시: 손글씨 숫자 인식 (MNIST)\\n\\n| 단계 | 내용 |\\n|------|------|\\n| **데이터** | 0~9 숫자 손글씨 이미지 60,000장 (학습) + 10,000장 (검증) |\\n| **모델** | 2~3개의 은닉층을 가진 간단한 신경망 |\\n| **학습** | 이미지 → 네트워크 → 10개의 출력(각 숫자 확률) → 손실 계산 → 가중치 업데이트 |\\n| **결과** | 99% 이상의 정확도로 새로운 손글씨 숫자를 맞춤 |\\n\\n---\\n\\n## 7. 요약 (핵심 포인트)\\n\\n1. **데이터 → 모델 → 손실 → 가중치 업데이트** 라는 순환이 학습의 핵심.\\n2. **경사 하강법**은 “오차가 가장 크게 줄어드는 방향으로 조금씩 움직이는” 방법.\\n3. **여러 번 반복(epochs)**하면서 모델이 점점 더 좋은 규칙(패턴)을 찾아냄.\\n4. **다층 구조와 비선형 함수**가 복잡한 문제(이미지, 음성, 언어)를 해결하게 함.\\n5. **많은 데이터와 연산 자원**이 있으면 더 정확하고 일반화된 모델을 만들 수 있음.\\n\\n---\\n\\n### 한 줄 정리  \\n> 인공지능 모델은 “많은 예시를 보면서 ‘이게 정답’이라고 알려주는 점수를 최소화하도록 가중치를 조금씩 바꾸는” 과정을 여러 번 반복해 스스로 규칙을 배우는 거예요.\\n\\n궁금한 부분이 있으면 언제든 물어보세요! 😊' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 1434, 'prompt_tokens': 87, 'total_tokens': 1521, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.202904147, 'prompt_time': 0.003051547, 'completion_time': 2.954196095, 'total_time': 2.957247642}, 'model_name': 'openai/gpt-oss-120b', 'system_fingerprint': 'fp_82669fd91d', 'id': 'chatcmpl-63053399-9b55-4ae4-94a6-7bd916402fbc', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--c3cdf906-e76c-416e-9c15-a664bb155187-0' usage_metadata={'input_tokens': 87, 'output_tokens': 1434, 'total_tokens': 1521, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WzcZy4PruV1n",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "id": "WzcZy4PruV1n",
    "outputId": "18ecc8f9-5748-4b16-cb07-4a0f7a01fb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 인공지능 모델, 특히 **머신러닝·딥러닝** 모델이 어떻게 배우는지 쉽게 풀어볼게요.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. 기본 아이디어: “경험을 통해 규칙을 찾는다”\n",
      "\n",
      "- **인간**: 아이가 사과와 바나나를 여러 번 보여주면서 “이건 사과, 저건 바나나”라고 알려주면, 나중에 새로운 과일을 보면 어느 쪽에 가까운지 스스로 판단하게 돼요.\n",
      "- **AI 모델**: 컴퓨터에게도 같은 “경험(데이터)”을 많이 주면, 스스로 “어떤 입력이 어떤 결과와 연결되는지”를 찾아냅니다.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. 구성 요소\n",
      "\n",
      "| 요소 | 설명 | 비유 |\n",
      "|------|------|------|\n",
      "| **데이터** | 모델이 학습할 때 보는 예시(이미지, 텍스트, 소리 등) | 아이가 보는 그림책 |\n",
      "| **모델(네트워크)** | 입력을 받아서 출력을 만드는 수식·구조(뉴런·가중치) | 아이의 뇌 속 회로망 |\n",
      "| **가중치(파라미터)** | 모델이 학습하면서 조정하는 숫자들 | 뇌 속 시냅스 강도 |\n",
      "| **손실 함수(Loss)** | 모델이 만든 답과 정답 사이의 차이를 수치화 | “얼마나 틀렸는지 점수” |\n",
      "| **최적화 알고리즘** | 가중치를 조금씩 바꿔 손실을 줄이는 방법 | “점수를 낮추려는 연습” |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. 학습 과정 (한 번의 **epoch** 예시)\n",
      "\n",
      "1. **데이터를 하나씩 꺼낸다**  \n",
      "   예) 고양이 사진 + “고양이” 라는 라벨을 가져옴.\n",
      "\n",
      "2. **모델에 입력한다**  \n",
      "   사진을 네트워크에 넣으면, 현재 가중치에 따라 “고양이일 확률”을 출력.\n",
      "\n",
      "3. **손실을 계산한다**  \n",
      "   - 모델이 0.7(70%)이라고 예측했는데 실제 정답은 1(100%) → 손실이 발생.\n",
      "   - 손실 함수(예: 교차 엔트로피)로 “얼마나 틀렸는지” 수치화.\n",
      "\n",
      "4. **가중치를 업데이트한다**  \n",
      "   - **역전파(backpropagation)** 라는 과정으로, 손실이 큰 방향(오차가 큰 부분)을 찾아 가중치를 조금씩 조정.\n",
      "   - **경사 하강법(Gradient Descent)** 은 “오차가 가장 크게 줄어드는 방향으로 한 걸음씩 움직이는” 방법.\n",
      "\n",
      "5. **전체 데이터를 다 돌면 한 번의 epoch**  \n",
      "   - 여러 epoch를 반복하면서 가중치가 점점 최적에 가까워짐.\n",
      "\n",
      "---\n",
      "\n",
      "## 4. 비유로 이해하기\n",
      "\n",
      "### “산을 오르는 등산가” 비유\n",
      "- **산** = 손실 함수가 만든 “오차 지형”. 가장 낮은 곳(밑바닥)이 최적점.\n",
      "- **등산가** = 최적화 알고리즘(경사 하강법). 현재 위치에서 가장 가파른 아래쪽을 찾아 한 걸음씩 내려감.\n",
      "- **여러 번 반복** = 여러 epoch. 등산가가 여러 번 산을 오르내리며 최저점(최적 가중치)을 찾음.\n",
      "\n",
      "### “요리 레시피 조정” 비유\n",
      "- **재료와 양** = 가중치.\n",
      "- **맛(정답과의 차이)** = 손실.\n",
      "- **시식 후 조정** = 역전파와 가중치 업데이트.\n",
      "- **반복** = 레시피를 여러 번 고쳐가며 최고의 맛을 찾음.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. 딥러닝(신경망)에서 특별히 중요한 점\n",
      "\n",
      "| 특징 | 설명 |\n",
      "|------|------|\n",
      "| **다층 구조** | 여러 층을 쌓아 복잡한 패턴을 단계별로 추출 (예: 가장자리 → 형태 → 물체) |\n",
      "| **비선형 활성함수** | ReLU, Sigmoid 등으로 복잡한 관계를 표현 |\n",
      "| **대량 데이터** | 데이터가 많을수록 일반화가 잘돼서 실제 상황에서도 잘 동작 |\n",
      "| **GPU 가속** | 수천·수만 개의 가중치를 빠르게 계산해 학습 속도 향상 |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. 간단한 예시: 손글씨 숫자 인식 (MNIST)\n",
      "\n",
      "| 단계 | 내용 |\n",
      "|------|------|\n",
      "| **데이터** | 0~9 숫자 손글씨 이미지 60,000장 (학습) + 10,000장 (검증) |\n",
      "| **모델** | 2~3개의 은닉층을 가진 간단한 신경망 |\n",
      "| **학습** | 이미지 → 네트워크 → 10개의 출력(각 숫자 확률) → 손실 계산 → 가중치 업데이트 |\n",
      "| **결과** | 99% 이상의 정확도로 새로운 손글씨 숫자를 맞춤 |\n",
      "\n",
      "---\n",
      "\n",
      "## 7. 요약 (핵심 포인트)\n",
      "\n",
      "1. **데이터 → 모델 → 손실 → 가중치 업데이트** 라는 순환이 학습의 핵심.\n",
      "2. **경사 하강법**은 “오차가 가장 크게 줄어드는 방향으로 조금씩 움직이는” 방법.\n",
      "3. **여러 번 반복(epochs)**하면서 모델이 점점 더 좋은 규칙(패턴)을 찾아냄.\n",
      "4. **다층 구조와 비선형 함수**가 복잡한 문제(이미지, 음성, 언어)를 해결하게 함.\n",
      "5. **많은 데이터와 연산 자원**이 있으면 더 정확하고 일반화된 모델을 만들 수 있음.\n",
      "\n",
      "---\n",
      "\n",
      "### 한 줄 정리  \n",
      "> 인공지능 모델은 “많은 예시를 보면서 ‘이게 정답’이라고 알려주는 점수를 최소화하도록 가중치를 조금씩 바꾸는” 과정을 여러 번 반복해 스스로 규칙을 배우는 거예요.\n",
      "\n",
      "궁금한 부분이 있으면 언제든 물어보세요! 😊\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5c97fc",
   "metadata": {},
   "source": [
    "### 2) PromptTemplate + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SeNi_VXqYD-b",
   "metadata": {
    "id": "SeNi_VXqYD-b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.prompts.prompt.PromptTemplate'>\n",
      "input_variables=['input'] input_types={} partial_variables={} template='You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.'\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "print(type(prompt))\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01WLucSpYjZt",
   "metadata": {
    "id": "01WLucSpYjZt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'langchain_core.messages.ai.AIMessage'>\n",
      "content='인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 사람의 뇌는 경험을 통해 학습하고, 인공지능 모델도 데이터를 통해 학습합니다.\\n\\n인공지능 모델의 학습 과정은 다음과 같습니다.\\n\\n1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다.\\n\\n2. **데이터 전처리**: 수집한 데이터를 전처리하여 모델이 학습하기 쉽게 변환합니다.\\n\\n3. **모델 초기화**: 인공지능 모델을 초기화합니다. 모델은 입력층, 은닉층, 출력층으로 구성되어 있습니다.\\n\\n4. **순전파**: 입력 데이터를 모델에 입력하여 출력값을 계산합니다. 이 과정을 순전파(forward propagation)라고 합니다.\\n\\n5. **오차 계산**: 모델의 출력값과 실제 답을 비교하여 오차를 계산합니다.\\n\\n6. **역전파**: 오차를 줄이기 위해 모델의 가중치를 업데이트합니다. 이 과정을 역전파(backward propagation)라고 합니다.\\n\\n7. **최적화**: 모델의 가중치를 업데이트하여 오차를 줄입니다. 이 과정을 최적화(optimization)라고 합니다.\\n\\n8. **반복**: 4~7단계를 반복하여 모델의 성능을 향상시킵니다.\\n\\n인공지능 모델은 학습 데이터를 통해 모델의 가중치를 업데이트하고, 이를 통해 새로운 데이터에 대한 예측 성능을 향상시킵니다.\\n\\n예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 학습시킨다고 가정해 봅시다. 모델은 고양이와 강아지의 사진을 입력받아서 고양이인지 강아지인지를 출력합니다. 모델은 사진을 입력받아서 고양이일 확률과 강아지일 확률을 계산합니다. 실제 답과 모델의 출력값을 비교하여 오차를 계산하고, 오차를 줄이기 위해 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델은 고양이와 강아지의 특징을 학습하고, 새로운 사진에 대한 분류 성능을 향상시킵니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 411, 'prompt_tokens': 36, 'total_tokens': 447, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': 0.206211411, 'prompt_time': 0.001130101, 'completion_time': 0.98423394, 'total_time': 0.985364041}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'id': 'chatcmpl-d6b41fc3-95a4-4d27-8fe6-6bbb55fa66d4', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None} id='run--2f089765-090b-4077-8661-ffd7ebfb7db3-0' usage_metadata={'input_tokens': 36, 'output_tokens': 411, 'total_tokens': 447, 'input_token_details': {}, 'output_token_details': {}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm\n",
    "print(type(chain))\n",
    "\n",
    "# chain 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "170ec878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 사람의 뇌는 경험을 통해 학습하고, 인공지능 모델도 데이터를 통해 학습합니다.\n",
      "\n",
      "인공지능 모델의 학습 과정은 다음과 같습니다.\n",
      "\n",
      "1. **데이터 수집**: 인공지능 모델을 학습시키기 위해 데이터를 수집합니다. 이 데이터는 문제에 대한 답을 포함하고 있어야 합니다.\n",
      "\n",
      "2. **데이터 전처리**: 수집한 데이터를 전처리하여 모델이 학습하기 쉽게 변환합니다.\n",
      "\n",
      "3. **모델 초기화**: 인공지능 모델을 초기화합니다. 모델은 입력층, 은닉층, 출력층으로 구성되어 있습니다.\n",
      "\n",
      "4. **순전파**: 입력 데이터를 모델에 입력하여 출력값을 계산합니다. 이 과정을 순전파(forward propagation)라고 합니다.\n",
      "\n",
      "5. **오차 계산**: 모델의 출력값과 실제 답을 비교하여 오차를 계산합니다.\n",
      "\n",
      "6. **역전파**: 오차를 줄이기 위해 모델의 가중치를 업데이트합니다. 이 과정을 역전파(backward propagation)라고 합니다.\n",
      "\n",
      "7. **최적화**: 모델의 가중치를 업데이트하여 오차를 줄입니다. 이 과정을 최적화(optimization)라고 합니다.\n",
      "\n",
      "8. **반복**: 4~7단계를 반복하여 모델의 성능을 향상시킵니다.\n",
      "\n",
      "인공지능 모델은 학습 데이터를 통해 모델의 가중치를 업데이트하고, 이를 통해 새로운 데이터에 대한 예측 성능을 향상시킵니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 학습시킨다고 가정해 봅시다. 모델은 고양이와 강아지의 사진을 입력받아서 고양이인지 강아지인지를 출력합니다. 모델은 사진을 입력받아서 고양이일 확률과 강아지일 확률을 계산합니다. 실제 답과 모델의 출력값을 비교하여 오차를 계산하고, 오차를 줄이기 위해 모델의 가중치를 업데이트합니다. 이 과정을 반복하여 모델은 고양이와 강아지의 특징을 학습하고, 새로운 사진에 대한 분류 성능을 향상시킵니다.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56848a4c",
   "metadata": {},
   "source": [
    "### 3) PromptTemplate + LLM(invoke()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d1e9009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableSequence'>\n",
      "<class 'str'>\n",
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. \n",
      "\n",
      "기본적으로 인공지능 모델은 데이터를 통해 학습합니다. 예를 들어, 이미지 분류 모델을 만들기 위해 고양이, 강아지, 자동차 등의 사진 데이터를 수집합니다.\n",
      "\n",
      "모델이 학습하는 과정은 다음과 같습니다.\n",
      "\n",
      "1.  데이터 수집: 인공지능이 학습할 수 있는 데이터를 수집합니다. 예를 들어, 사진, 텍스트, 음성 등 다양한 형태의 데이터가 될 수 있습니다.\n",
      "2.  데이터 전처리: 수집한 데이터를 정제하고 가공하여 모델이 학습할 수 있는 형태로 만듭니다. 예를 들어, 이미지 데이터의 경우, 이미지의 크기를 조정하거나 노이즈를 제거하는 등의 작업이 필요합니다.\n",
      "3.  모델 선택: 수집한 데이터를 바탕으로 적합한 인공지능 모델을 선택합니다. 예를 들어, 이미지 분류 모델을 만들기 위해 컨볼루션 신경망(CNN)과 같은 모델을 선택할 수 있습니다.\n",
      "4.  학습: 선택한 모델에 데이터를 입력하고, 모델이 데이터를 분석하고 학습할 수 있도록 합니다. 이 과정에서 모델은 데이터의 패턴이나 관계를 학습하고, 이를 바탕으로 예측이나 분류를 수행할 수 있습니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 모델에 고양이와 강아지의 사진을 보여주고, 이것이 고양이인지 강아지인지를 알려줍니다. 처음에는 모델이 고양이와 강아지를 구분하지 못하지만, 많은 사진을 학습하면서 고양이와 강아지의 특징을 스스로 학습합니다. \n",
      "\n",
      "이처럼 인공지능 모델은 많은 데이터를 학습하면서 데이터의 패턴이나 관계를 학습하고, 이를 바탕으로 예측이나 분류를 수행할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# 2. chain 생성 (LCEL)\n",
    "chain = prompt | llm | output_parser\n",
    "print(type(chain))\n",
    "\n",
    "# 3. chain의 invoke 호출\n",
    "result = chain.invoke({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "print(type(result))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d997b16",
   "metadata": {},
   "source": [
    "### 4) PromptTemplate + LLM(stream()) + StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "684654e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인공지능 모델의 학습 원리는 사람의 뇌가 학습하는 원리와 유사합니다. 컴퓨터가 데이터를 통해 스스로 학습할 수 있도록 하는 것입니다.\n",
      "\n",
      "예를 들어, 고양이와 강아지의 사진을 분류하는 모델을 만든다고 가정해 봅시다. 이 모델에게 고양이와 강아지의 사진을 여러 장 보여주고, 이것이 고양이인지 강아지인지를 알려줍니다. 처음에는 모델이 고양이와 강아지를 구분하지 못하지만, 사진을 계속 보여주고 정답을 알려주면 모델은 스스로 고양이와 강아지의 특징을 학습합니다.\n",
      "\n",
      "즉, 모델은 데이터(고양이와 강아지의 사진)와 정답(고양이 또는 강아지)을 통해 학습합니다. 이 학습 과정을 통해 모델은 새로운 사진을 봤을 때 그것이 고양이인지 강아지인지를 예측할 수 있습니다.\n",
      "\n",
      "이러한 학습 과정은 다음과 같은 단계로 이루어집니다.\n",
      "\n",
      "1.  **데이터 수집**: 인공지능이 학습할 데이터를 수집합니다. 예를 들어, 고양이와 강아지의 사진입니다.\n",
      "2.  **데이터 전처리**: 수집한 데이터를 인공지능이 학습할 수 있도록 가공하는 과정입니다. 예를 들어, 사진의 크기를 조정하거나 노이즈를 제거하는 것입니다.\n",
      "3.  **모델 훈련**: 데이터를 통해 인공지능 모델을 훈련하는 과정입니다. 이 과정에서 모델은 데이터의 패턴을 학습하고, 고양이와 강아지의 특징을 구분합니다.\n",
      "4.  **모델 평가**: 훈련된 모델의 성능을 평가하는 과정입니다. 이 과정에서는 모델이 새로운 데이터를 봤을 때 얼마나 정확하게 고양이와 강아지를 구분하는지 평가합니다.\n",
      "5.  **모델 배포**: 평가를 통해 성능이 검증된 모델을 실제 환경에 배포하는 과정입니다. 이 과정을 통해 모델은 새로운 데이터를 실시간으로 처리하고, 고양이와 강아지를 구분할 수 있습니다.\n",
      "\n",
      "인공지능 모델의 학습 원리는 이처럼 데이터와 정답을 통해 모델을 학습시키고, 모델이 새로운 데이터를 처리할 수 있도록 하는 것입니다. 이를 통해 인공지능 모델은 다양한 분야에서 활용될 수 있습니다."
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# 1. 컴포넌트 정의\n",
    "prompt = PromptTemplate.from_template(\"You are an expert in AI Expert. Answer the question. <Question>: {input}에 대해 쉽게 설명해주세요.\")\n",
    "\n",
    "#llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "lm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model = \"openai/gpt-oss-120b\",                # GPT-OSS-120B\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# chain 연결 (LCEL)\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# 스트리밍 출력을 위한 요청, invoke()가 아닌 Stream()\n",
    "answer = chain.stream({\"input\": \"인공지능 모델의 학습 원리\"})\n",
    "# 스트리밍 출력\n",
    "#print(answer)\n",
    "\n",
    "for token in answer:\n",
    "    # 스트림에서 받은 데이터의 내용을 출력합니다. 줄바꿈 없이 이어서 출력하고, 버퍼를 즉시 비웁니다.\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0188674-915f-41af-ac46-56f9f54289b0",
   "metadata": {
    "id": "b0188674-915f-41af-ac46-56f9f54289b0"
   },
   "source": [
    "##### 2) Multiple Chains\n",
    "* Multi Chain을 활용한 영화 추천 및 줄거리 요약"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "31678c55-38a8-4ca2-b437-9d4495946b0a",
    "outputId": "7ee83878-5d1a-45e3-f033-100da33f3ee9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n",
      " ===> 추천된 영화:\n",
      "**추천 영화: 《소울 (Soul)》 (2020)**  \n",
      "\n",
      "- **감독**: 피트 도크터(Pete Docter)  \n",
      "- **주연**: 제이미 폭스, 티나 페이, 케이트 블란쳇 등  \n",
      "- **줄거리**: 뉴욕의 재즈 피아니스트 조 가드너는 꿈에 그리던 재즈 클럽에서 연주할 기회를 얻게 된다. 그러나 갑작스러운 사고로 영혼이 ‘전후 세계’인 ‘그레이트 플레인’으로 이동하게 되고, 여기서 ‘생명의 불꽃’과 ‘목적’에 대해 다시 생각하게 된다. 조는 다시 지구로 돌아가 자신의 삶을 새롭게 살아가려는 여정을 시작한다.  \n",
      "\n",
      "- **추천 이유**  \n",
      "  1. **깊이 있는 인간 드라마**: 삶의 의미, 꿈과 현실 사이의 갈등, 그리고 ‘진정한 행복’이 무엇인지에 대한 사색을 감동적으로 풀어냅니다.  \n",
      "  2. **시각적·음악적 아름다움**: 픽셀 애니메이션 특유의 섬세한 색감과 재즈 음악이 조화를 이루어, 눈과 귀 모두를 사로잡습니다.  \n",
      "  3. **다양한 연령층이 공감**  \n",
      "     - 청춘에게는 “꿈을 포기하지 말라”는 메시지를,  \n",
      "     - 성인에게는 “일상 속 작은 순간을 놓치지 말라”는 위로를 줍니다.  \n",
      "  4. **수상 경력**: 아카데미 시상식에서 ‘최우수 애니메이션 영화’와 ‘최우수 원곡상(‘소울’ – 트랜스코드)’을 수상하며, 비평가와 관객 모두에게 큰 호평을 받았습니다.  \n",
      "\n",
      "> **한 줄 요약**: 삶과 꿈, 그리고 존재의 의미를 따뜻하고 섬세한 애니메이션으로 풀어낸 ‘소울’은 드라마 장르에서 놓칠 수 없는 감동적인 작품입니다.  \n",
      "\n",
      "※ 감상 시, 조용한 환경에서 눈과 귀를 모두 열고 보시면 더 큰 울림을 느끼실 수 있어요. 즐거운 감상 되세요!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "# llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    # model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    model = \"openai/gpt-oss-120b\",                # GPT-OSS-120B\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "movie = chain1.invoke({\"genre\": \"Drama\"})  # 영화 제목 얻기\n",
    "\n",
    "print(type(movie))\n",
    "print(\" ===> 추천된 영화:\")  # movie 값 출력\n",
    "print(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "16718b76-f59d-48f7-906f-5d2371417803",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "16718b76-f59d-48f7-906f-5d2371417803",
    "outputId": "6e3371cd-d294-4be7-a868-2eae5ee6e5de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first={\n",
      "  movie: ChatPromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['genre'], input_types={}, partial_variables={}, template='{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.'), additional_kwargs={})])\n",
      "         | ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')\n",
      "         | StrOutputParser()\n",
      "} middle=[ChatPromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['movie'], input_types={}, partial_variables={}, template='{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요'), additional_kwargs={})]), ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x0000026619932930>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x00000266199215B0>, root_client=<openai.OpenAI object at 0x0000026627D7B3E0>, root_async_client=<openai.AsyncOpenAI object at 0x0000026619922F60>, model_name='meta-llama/llama-4-scout-17b-16e-instruct', temperature=0.7, model_kwargs={}, openai_api_key=SecretStr('**********'), openai_api_base='https://api.groq.com/openai/v1')] last=StrOutputParser()\n",
      "\n",
      "🔹 영화 줄거리 요약:\n",
      " The  Notebook \n",
      "\n",
      "*   **감독** : 닉  카사베츠 \n",
      "*   **캐스팅** : 라이언 고슬링  , 레이철 맥애덤스 \n",
      "*   **줄거리** : '노트북'은 니콜라스 스파크스의 소설을 원작으로 하는 영화입니다. 이 영화는1940년대와1990년대의 두 시기에 걸쳐 사랑과 인생의 복잡성을 다루고 있습니다. 노아(라이언 고슬링)와 앨리(레이철 맥애덤스)는 여름 캠프에서 처음 만나 사랑에 빠지게 됩니다. 하지만 앨리의 부모는 노아의 사회적 지위가 낮다는 이유로 두 사람의 사랑을 반대합니다. 이에 앨리는 노아와의 만남을 중단하고, 노아는 앨리를 잊지 않기 위해365일간 매일 편지를 보냅니다. 앨리는 다른 남자와 약혼하지만, 노아와의 추억을 잊지 못합니다. 마침내 앨리는 노아의 편지를 읽고, 노아를 찾아가게 됩니다. 두 사람은 다시 만나 사랑을 재확인하고, 앨리는 노아와의 약속을 지키기 위해 노아와 결혼합니다. 이 영화는 사랑, 희생, 그리고 인생의 기쁨과 슬픔을 다루고 있습니다. 아름다운 영상과 감동적인 이야기로 많은 사랑을 받고 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "print(chain2)\n",
    "\n",
    "# 실행: \"SF\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\\n\", response) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb684fd",
   "metadata": {},
   "source": [
    "##### chain1과 chain2에서 영화 제목이 일관되게 전달 되도록 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30883ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 영화 줄거리 요약:\n",
      "('영화: <매드 맥스: 분노의 질주>\\n'\n",
      " '\\n'\n",
      " '장르: 액션, 드라마, 코미디\\n'\n",
      " '\\n'\n",
      " '줄거리: 맥스 로킨스턴은 고속도로 경부대로 근무하던 중, 오일 필드에서 일하던 일당이 사제 총기를 쏴대며 나타납니다. 이후 맥스는 '\n",
      " '도망치던 중, 토레타가의 여주인 임퍼레이터 퓨리오사에게 구조를 받게 됩니다. 하지만 토레타가에는 퓨리오사가 잡혀 있는 상태였고, '\n",
      " '퓨리오사는 자기가 이끄는 부족을 구하기 위해 고향으로 돌아가려던 중이었습니다. 맥스는 퓨리오사의 부족과 함께 퓨리오사의 고향으로 돌아가는 '\n",
      " '여정에 동행하게 됩니다. 하지만 그들의 여정에 토레타가의 수장인 이모터란이 방해를 가합니다.\\n'\n",
      " '\\n'\n",
      " '감독: 조지 밀러\\n'\n",
      " '\\n'\n",
      " '캐스팅: \\n'\n",
      " '- 톰 하디 (맥스 역)\\n'\n",
      " '- 샤를리즈 테론 (임퍼레이터 퓨리오사 역)\\n'\n",
      " '- 니콜라스 홀트 (임모탄 조 역)\\n'\n",
      " '\\n'\n",
      " '추천 이유: 영화는 고옥탄 액션과 유머러스한 장면으로 가득 차 있습니다. 주인공인 맥스는 과거의 트라우마를 극복하고 새로운 동료들과 함께 '\n",
      " '성장하는 모습을 보여줍니다. 또한, 영화는 사막에서 벌어지는 자동차 경주와 폭주 장면으로 눈을 사로잡습니다.')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "# Step 1: 사용자가 입력한 장르에 따라 영화 추천\n",
    "prompt1 = ChatPromptTemplate.from_template(\"{genre} 장르에서 추천할 만한 영화를 한 편 알려주세요.\")\n",
    "\n",
    "# Step 2: 추천된 영화의 줄거리를 요약\n",
    "prompt2 = ChatPromptTemplate.from_template(\"{movie} 추천한 영화의 제목을 먼저 알려주시고, 줄을 바꾸어서 영화의 정보(제목,감독,캐스팅,줄거리)를 알려 주세요.\")\n",
    "\n",
    "# OpenAI 모델 사용\n",
    "llm = ChatOpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.groq.com/openai/v1\",  # Groq API 엔드포인트\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",  # Spring AI와 동일한 모델\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "# 체인 1: 영화 추천 (입력: 장르 → 출력: 영화 제목)\n",
    "chain1 = prompt1 | llm | StrOutputParser()\n",
    "\n",
    "# 체인 2: 줄거리 요약 (입력: 영화 제목 → 출력: 줄거리)\n",
    "chain2 = (\n",
    "    {\"movie\": chain1}  # chain1의 출력을 movie 변수로 전달\n",
    "    | prompt2\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# 실행: \"Drama\" 장르의 영화 추천 및 줄거리 요약\n",
    "response = chain2.invoke({\"genre\": \"Drama\"})\n",
    "print(\"\\n🔹 영화 줄거리 요약:\")\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
